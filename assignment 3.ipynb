{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "data = pd.read_csv(r'data.csv')\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)\n",
    "df.tail(3)\n",
    "df.shape\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check unique cols in df\n",
    "for col in df.columns:\n",
    "    if df[col].is_unique:\n",
    "        print(f'Unique Column : {col} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset indexes\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null counts\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop null values\n",
    "df = df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.review_profileName.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by \"review_overall\" in descending order\n",
    "df = df.sort_values('review_overall', ascending=False)\n",
    "\n",
    "# keep the highest rating from each \"review_profilename\" and drop the rest\n",
    "df = df.drop_duplicates(subset= ['review_profileName','beer_beerId'], keep='first')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Rank top 3 Breweries which produce the strongest beers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# group by brewerId and calculate the average ABV for each brewery\n",
    "brewery_avg_abv = df.groupby('beer_brewerId')['beer_ABV'].mean()\n",
    "\n",
    "# sort breweries by average ABV in descending order and select the top 3\n",
    "top_3_breweries = brewery_avg_abv.sort_values(ascending=False).head(3)\n",
    "\n",
    "print(\"Top 3 Breweries Producing the Strongest Beers:\")\n",
    "print(top_3_breweries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Which year did beers enjoy the highest ratings? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert review_time to datetime\n",
    "df['review_time'] = pd.to_datetime(df['review_time'], unit='s')\n",
    "\n",
    "# extract year from review_time\n",
    "df['year'] = df['review_time'].dt.year\n",
    "\n",
    "# group by year and calculate the average rating for each year\n",
    "average_ratings_by_year = df.groupby('year')['review_overall'].mean()\n",
    "\n",
    "# find the year with the highest average rating\n",
    "highest_rated_year = average_ratings_by_year.idxmax()\n",
    "\n",
    "print(\"Year with the highest average ratings for beers:\", highest_rated_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Based on the userâ€™s ratings which factors are important among taste, aroma, appearance, and palette?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_matrix = df[['review_taste', 'review_aroma', 'review_appearance', 'review_palette', 'review_overall']].corr()\n",
    "\n",
    "# Extract correlations with review_overall\n",
    "correlations_with_overall = correlation_matrix['review_overall'].drop('review_overall')\n",
    "\n",
    "# Sort correlations in descending order\n",
    "sorted_correlations = correlations_with_overall.sort_values(ascending=False)\n",
    "\n",
    "print(\"Correlation between each factor and overall review rating:\")\n",
    "print(sorted_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so review_aroma has highest corellation which is important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. If you were to recommend 3 beers to your friends based on this data which ones will you recommend? * need to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning custom weights\n",
    "weights = {'review_overall': 0.4, 'review_taste': 0.2, 'review_aroma': 0.1, 'review_appearance': 0.1, 'review_palette': 0.2}\n",
    "df['weighted_rating'] = (df[list(weights.keys())] * pd.Series(weights)).sum(axis=1)\n",
    "\n",
    "# sort beers by weighted rating in descending order\n",
    "recommended_beers = df.sort_values(by='weighted_rating', ascending=False).head(3)\n",
    "\n",
    "print(\"Recommended beers for my friends:\")\n",
    "#print(recommended_beers[['beer_name', 'weighted_rating', 'review_text']])\n",
    "recommended_beers[['beer_name', 'weighted_rating', 'review_text']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how the weights were calculated:\n",
    "\n",
    "Review Overall: This factor represents the overall review rating given by users. Since it reflects the overall satisfaction with the beer, it was assigned the highest weight of 0.4.\n",
    "Review Taste: Taste is a crucial aspect of beer enjoyment, so it was assigned a weight of 0.2, reflecting its importance in the overall rating.\n",
    "Review Aroma: Aroma contributes significantly to the sensory experience of drinking beer, but it may be slightly less important than taste. Therefore, it was assigned a weight of 0.1.\n",
    "Review Appearance: While appearance can influence the initial impression of a beer, its impact on overall enjoyment may be somewhat lower compared to taste and aroma. Hence, it was assigned a weight of 0.1.\n",
    "Review Palette: Palette, which likely refers to the mouthfeel or texture of the beer, was also considered important but slightly less so compared to taste and aroma. Therefore, it was assigned a weight of 0.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Which Beer style seems to be the favorite based on reviews written by users? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking relevant columns\n",
    "reviewTextData = data[['beer_beerId','beer_name','beer_ABV','beer_style','review_overall','review_text']]\n",
    "\n",
    "# taking higher ranked reviews only >/=4 (from the overall reviews column)\n",
    "reviewTextData = reviewTextData.loc[reviewTextData['review_overall'] >= 4]\n",
    "\n",
    "# resetting Index\n",
    "reviewTextData.reset_index(drop=True,inplace=True)\n",
    "\n",
    "reviewTextData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextData.review_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text preprocessing\n",
    "import re\n",
    "\n",
    "# initial text processing replacing short forms\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"it\\'s\", \"it is\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    \n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting text reviews and applying text preprocessing on it\n",
    "preprocessed_reviews = []\n",
    "\n",
    "for sentance in tqdm(reviewTextData['review_text'].values): # tqdm prints the status bar\n",
    "    sentance = decontracted(sentance) # deconstructiong short forms\n",
    "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip() # remove words with numbers \n",
    "    \n",
    "    preprocessed_reviews.append(sentance) # form sentence again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending preprocessed reviews to the filtered dataframe\n",
    "reviewTextData['preprocessed_review_text'] = preprocessed_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating Sentiment Analyzer\n",
    "sianalyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# loop over the 'preprocessed_review_text' column and calculate the polarity score for each review\n",
    "reviewTextData['polarity_score2'] = reviewTextData['preprocessed_review_text'].progress_apply(lambda x: sianalyzer.polarity_scores(x)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping and calculate mean polarity score.\n",
    "reviewTextDataGroupped = reviewTextData.groupby('beer_style')['polarity_score2'].mean()\n",
    "\n",
    "# sort the grouped data by mean polarity score\n",
    "reviewTextDataGroupped.sort_values(ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observing the top 'polarity_score2' and 'beer_beerId' associated with i\n",
    "reviewTextData.loc[reviewTextData['beer_style'] == 'Dortmunder / Export Lager']\n",
    "reviewTextData.loc[reviewTextData['beer_style'] == 'American Blonde Ale']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By observing the mean compound polarity score , we can say that the beer style \"Dortmunder / Export Lager\" is liked most but has only one person that likes it as much, we can instead say \"American Blonde Ale\" is the most famous, based on combination of polarity and higher frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. How does written review compare to overall review score for the beer styles?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By observing the mean compound polarity score calculated we can get an idea how the user written review text is collaborating in calculating the overall review score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. How to find similar beer drinkers by using written reviews only?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewTextData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction\n",
    "# Initialize TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the preprocessed text data to create TF-IDF features\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(reviewTextData['preprocessed_review_text'])\n",
    "\n",
    "# Step 3: Similarity Calculation\n",
    "# Calculate cosine similarity between user reviews\n",
    "cosine_similarities = cosine_similarity(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping together similiar customers based on reviews\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "clusters = kmeans.fit_predict(cosine_similarities)\n",
    "\n",
    "# Step 3: Analyze cluster assignments\n",
    "# Assign each user to a cluster\n",
    "user_clusters = {}\n",
    "\n",
    "for user_id, cluster_id in enumerate(clusters):\n",
    "    if cluster_id not in user_clusters:\n",
    "        user_clusters[cluster_id] = []\n",
    "    user_clusters[cluster_id].append(user_id)\n",
    "\n",
    "# Print the users in each cluster\n",
    "for cluster_id, users in user_clusters.items():\n",
    "    print(f\"Cluster {cluster_id}: {users}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
